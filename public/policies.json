[
  {
    "index": 1,
    "title": "International Compute Sharing",
    "description": "Access to compute is a key driver of AI performance and deployment, yet its growing cost — driven by high demand and limited supply of specialized chips — threaten to deepen global AI inequality. Proposed policy responses include pooling compute resources through international cooperation, akin to CERN, or subsidizing access for developers in low-income countries to promote innovation. These strategies, while promising, face major hurdles such as steep costs, potential constraints on cutting-edge progress, and concerns over security and the broad distribution of powerful AI capabilities.",
    "references": "Ways Forward for Global AI Benefit Sharing",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 2,
    "title": "AI Talent Sharing",
    "description": "Technical expertise is a vital yet unevenly distributed resource in AI development, with low- and middle-income countries struggling due to limited educational infrastructure and investment. To bridge this gap, international cooperation through capacity-building programs has been proposed, aiming to support member states in expanding education and training in AI-related disciplines—following a model used in other advanced technology sectors.",
    "references": "Ways Forward for Global AI Benefit Sharing",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 3,
    "title": "Open Training Data",
    "description": "Access to high-quality data and training procedures is essential for developing advanced AI systems, yet much of this information remains proprietary. While open initiatives like LAION and CommonCrawl exist, the most powerful models are built on restricted datasets. Increasing transparency and sharing of these resources could democratize AI development and accelerate innovation on a global scale.",
    "references": "Ways Forward for Global AI Benefit Sharing",
    "type": "Mixed",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 4,
    "title": "Common AI Access",
    "description": "Another strategy to reduce AI inequality involves expanding access to advanced AI systems through open-source releases, APIs, or application-level tools. Although some access is already available globally, significant cost barriers remain for large-scale use. Investing in research to improve inference efficiency could help lower these costs, broadening practical access to powerful AI technologies.",
    "references": "Ways Forward for Global AI Benefit Sharing",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 5,
    "title": "AI Model Subsidy",
    "description": "Governments can help reduce AI inequality by subsidizing access to advanced AI tools and APIs using public funds. While such subsidies are often easier to administer within national borders, there are historical examples of successful international subsidy frameworks that could inform similar efforts in the AI domain.",
    "references": "Ways Forward for Global AI Benefit Sharing",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 6,
    "title": "Differential Pricing Models",
    "description": "Adopting region-based pricing for AI services could enhance global accessibility, following models already used by cloud and streaming platforms. However, this approach faces obstacles such as user manipulation of regional pricing and potential revenue losses for providers, making its implementation more complex in the AI context",
    "references": "Ways Forward for Global AI Benefit Sharing",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 7,
    "title": "IP Reform Levers",
    "description": "Adjusting intellectual property rights, such as shortening patent durations, can help redistribute the surplus from innovation more broadly. By reducing the exclusive period during which innovators capture most of the gains, a larger share of the economic benefits—especially from cost-saving technologies—can flow to workers and consumers. This approach aims to mitigate wage suppression and ensure that the positive impacts of innovation are more equitably shared across society.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 8,
    "title": "Anti-trust Policies",
    "description": "A growing policy movement across jurisdictions is pushing for stronger enforcement of competition law to check the power of dominant tech firms. With key appointments and legislative efforts in the U.S., EU, and other countries, authorities are embracing both structural and behavioral remedies. Competition law offers tools for proactive intervention to prevent excessive market concentration and for reactive enforcement to address abuses, aiming to rebalance power in the digital economy and foster fairer market conditions.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Competition"
  },
  {
    "index": 9,
    "title": "Data Frictionism",
    "description": "To sustain incentives for future knowledge production in the age of AI, policymakers must draw a distinction between past and future information. While cultural and intellectual materials from before 2000 could be opened more widely, future content requires new protections. Traditional IP frameworks may be inadequate to address the rapid appropriation of individual knowledge by AI systems. Instead, the path forward likely involves novel technical mechanisms that enable creators to control and monitor how their information is accessed and used—offering finer-grained alternatives to existing legal structures in a landscape where states may struggle to respond effectively.",
    "references": "https://www.radicalxchange.org/media/blog/open-maxis-and-new-frictionists/",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Competition"
  },
  {
    "index": 10,
    "title": "Curb Data Mergers",
    "description": "Modern competition policy must account for how firms use data accumulation and commercial surveillance to strengthen market dominance. Regulators increasingly recognize that data practices create significant information asymmetries, giving tech companies a competitive edge while compromising user privacy. A key strategy in this dynamic is the acquisition of other firms to consolidate data assets, exemplified by Google’s 2008 purchase of DoubleClick. Such data mergers have become a common tactic for expanding power in digital markets, underscoring the need for antitrust scrutiny that centers data as a critical asset.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Competition"
  },
  {
    "index": 11,
    "title": "Industrial Policy for Competition",
    "description": "The U.S. must move beyond a “national champions” mindset that shields dominant tech firms from regulation under the guise of national interest. Instead, a bold antitrust strategy is needed to foster a more competitive and dynamic digital ecosystem. While the EU has aggressively pursued Big Tech to restore market balance and support its own industrial priorities, the U.S. has often conflated corporate expansion with national success. A reoriented industrial policy would treat robust competition—not unchecked monopolies—as central to both economic resilience and democratic accountability.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Competition"
  },
  {
    "index": 12,
    "title": "The Windfall Clause",
    "description": "The Windfall Clause is a proposed mechanism requiring leading AI companies to share a portion of their profits that exceed predetermined, high thresholds—potentially tied to a significant share of global economic output. These surplus profits could be redistributed through a trust or global oversight body, aiming to ensure that the economic benefits of advanced AI are broadly and fairly shared across society.",
    "references": "https://www.governance.ai/research-paper/the-windfall-clause-distributing-the-benefits-of-ai-for-the-common-good",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 13,
    "title": "AI Growth Bond",
    "description": "To address sluggish productivity and rising inequality, a country could introduce an AI bond as a dual-purpose financial instrument. This bond would mobilize public and private investment into the AI sector while redistributing the resulting returns across the country. By capturing agglomeration effects and innovation spillovers, the bond aims to correct market underinvestment and ensure that the benefits of AI growth reach broader segments of the population.",
    "references": "https://britishprogress.org/uk-day-one/designing-an-ai-bond-for-growth-and-shared-prosper",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 14,
    "title": "Strategic Stakes",
    "description": "The U.S. government could seek limited influence over private technology labs by acquiring a minority shareholding, typically through stock purchases or targeted capital injections. Holding a 10–25% stake would grant the government a voice in corporate strategy and decision-making without assuming full control, offering a market-based approach to aligning company actions with public interest objectives.",
    "references": "https://www.convergenceanalysis.org/publications/soft-nationalization-how-the-us-government-will-control-ai-labs",
    "type": "Mixed",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 15,
    "title": "AI Golden Shares",
    "description": "The U.S. government could implement golden shares—a special class of equity that grants veto power over critical corporate decisions. This mechanism, historically used during privatizations, would enable the government to block actions perceived as threats to national interests while allowing the company to remain largely under private ownership and control.",
    "references": "https://www.convergenceanalysis.org/publications/soft-nationalization-how-the-us-government-will-control-ai-labs",
    "type": "Mixed",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 16,
    "title": "State Majority Ownership",
    "description": "By acquiring a majority voting stake in private technology labs, the U.S. government would gain effective control over their operations and strategic direction. This approach allows the state to steer key decisions while still permitting private investment, offering a hybrid model of public oversight and market participation similar to past interventions like the General Motors bailout.",
    "references": "https://www.convergenceanalysis.org/publications/soft-nationalization-how-the-us-government-will-control-ai-labs",
    "type": "Mixed",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 17,
    "title": "Full Nationalization",
    "description": "A complete government acquisition of a private lab would transfer all ownership to the state, repaying investors and easing the shift toward a fully public enterprise. This approach, exemplified by the nationalization of Conrail, eliminates private control altogether, granting the government total authority over operations, strategy, and long-term direction.",
    "references": "https://www.convergenceanalysis.org/publications/soft-nationalization-how-the-us-government-will-control-ai-labs",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 18,
    "title": "AI Taxation Framework",
    "description": "Building on the OECD’s BEPS 2.0 initiative, a proposed framework targets the taxation of transformative AI (TAI) systems that significantly displace labor. Modeled after Pillars One and Two, the proposal introduces a higher global minimum tax rate specifically for TAI, ensuring such systems contribute adequately to public revenues. It calls for the creation of an advisory board to define qualifying TAI, an international taxation regime based on profit thresholds and usage location, and revenue sourcing rules that allocate taxes to the countries where the systems are deployed. This approach aims to offset declining income tax revenues by ensuring TAI profits are equitably and effectively taxed.",
    "references": "https://docs.google.com/document/d/1boBVWe6nnN1ygeLh_Hcf0mKlqRWqdCk3obWXOLYOeeo/edit?tab=t.0",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 19,
    "title": "Transition Support Fund",
    "description": "Using revenue from increased corporate taxes on advanced systems, the U.S. could establish a dedicated fund to support workers affected by technological displacement. This fund would provide extended unemployment benefits, healthcare and housing assistance, and targeted retraining programs, particularly for those in industries heavily impacted by automation. The goal is to cushion the economic disruption caused by AI while enabling long-term workforce adaptation.",
    "references": "https://docs.google.com/document/d/1boBVWe6nnN1ygeLh_Hcf0mKlqRWqdCk3obWXOLYOeeo/edit?tab=t.0",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 0,
    "channel": "Redistribution"
  },
  {
    "index": 20,
    "title": "Robot Tax",
    "description": "A robot tax on companies using autonomous AI and robotics serves a dual purpose: it funds support systems for workers displaced by automation and creates an economic counterweight to indiscriminate labor replacement. By making automation less financially automatic in borderline cases, the tax encourages firms to more carefully consider the relative benefits of human versus machine labor, helping to preserve employment, consumer demand, and overall economic stability.",
    "references": "https://www.brookings.edu/articles/navigating-the-future-of-work-a-case-for-a-robot-tax-in-the-age-of-ai/",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 21,
    "title": "Universal Basic Services",
    "description": "Universal Basic Services (UBS) offers an alternative to Universal Basic Income by emphasizing guaranteed access to essential public services—such as housing, care, transport, information, and nutrition—based on need rather than ability to pay. Framed as more egalitarian, sustainable, and politically feasible in the context of climate and social challenges, UBS seeks to expand the principles already embedded in health and education systems. By ensuring sufficient resources for participation and well-being, UBS promotes collective security and social cohesion through publicly provided infrastructure.",
    "references": "https://en.unesco.org/inclusivepolicylab/analytics/move-debate-universal-basic-income-universal-basic-services",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 0,
    "channel": "Redistribution"
  },
  {
    "index": 22,
    "title": "Universal Basic Income",
    "description": "In the context of accelerating AI-driven automation, Universal Basic Income (UBI) offers a vital safety net for individuals displaced from the workforce. By providing unconditional financial support, it mitigates the economic shock of job loss without the stigma or hurdles of means-tested programs. UBI also affirms the societal value of non-market labor—such as caregiving—by offering financial recognition to those performing essential yet traditionally unpaid roles, reinforcing social equity amid technological change.",
    "references": "Documentation | OpenResearch",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 2,
    "channel": "Redistribution"
  },
  {
    "index": 23,
    "title": "Universal Basic Assets",
    "description": "With automation and AI disrupting traditional employment and income structures, a new policy framework is needed to foster deeper social and economic equity. Rather than relying solely on redistribution after wealth is accumulated, the focus must shift toward equalizing access to primary assets. As scholars like Thomas Piketty have argued, ensuring more equitable asset ownership is crucial in a world where returns increasingly favor capital holders. Emerging design strategies aim to broaden access to these foundational assets, laying the groundwork for more sustainable and inclusive economic participation.",
    "references": "IFTF - Universal Basic Assets",
    "type": "Public Policy",
    "aiWorld": "AI as Super Technology",
    "level": 1,
    "channel": "Redistribution"
  },
  {
    "index": 24,
    "title": "Capital Tax Reform",
    "description": "Reforming capital taxation—by eliminating interest deductions and taxing capital directly—can shift innovation incentives away from labor-displacing technologies. By raising the cost of capital, such policies encourage firms to pursue capital-augmenting innovations that enhance rather than replace human labor, potentially aligning technological progress with broader employment goals.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "AI-labor Complementarity"
  },
  {
    "index": 25,
    "title": "Targeted Redistribution",
    "description": "For low-skilled workers adversely affected by innovation, direct support through targeted public spending—funded by taxes on high rents from innovation—can offer more meaningful relief than general price reductions. Since wealthier individuals benefit more from lower prices due to their greater spending capacity, redistributive programs are better positioned to offset the unequal gains and cushion the economic impact on vulnerable labor segments.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 26,
    "title": "Wage Subsidies",
    "description": "To offset wage declines faced by workers displaced by automation, especially in low-skilled roles, governments can implement wage subsidy programs. These subsidies help maintain income levels by supplementing earnings, making displaced workers more attractive to employers and supporting their reintegration into the labor market without deepening inequality.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 27,
    "title": "Income Tax Credits",
    "description": "Income tax credits offer another tool to cushion wage losses for workers displaced by automation, particularly in low-skilled occupations. By boosting take-home pay without increasing labor costs for employers, tax credits can help sustain living standards and reduce the financial strain of technological displacement.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 28,
    "title": "Minimum Wage Reform",
    "description": "In labor markets where employers hold disproportionate bargaining power, raising the minimum wage can serve as a corrective measure to ensure full-time workers are not trapped in poverty. This policy strengthens the earnings floor and helps rebalance negotiating dynamics, promoting greater fairness in wage distribution.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 29,
    "title": "Higher Public Sector Wages",
    "description": "Raising wages in the public sector, along with increased public investment and spending, can stimulate demand for low-skilled labor. These measures not only create direct employment opportunities but also exert upward pressure on wages across the broader economy, contributing to more equitable income distribution and labor market resilience.",
    "references": "NBER WORKING PAPER SERIES ARTIFICIAL INTELLIGENCE AND ITS IMPLICATIONS FOR INCOME DISTRIBUTION AND UNEMPLOYMENT Anton Korinek Jo",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 30,
    "title": "Restrain Workplace Surveillance",
    "description": "To strengthen worker power, policy must address the harms of algorithmic management and workplace surveillance, which often justify unfair pay decisions, compromise safety, invade privacy, and suppress organizing efforts. Enforcing bright-line rules and establishing no-go zones for the most invasive practices would help restore balance between employers and workers, limiting the unchecked influence of surveillance technologies in shaping workplace conditions.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 2,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 31,
    "title": "Empowering Unions",
    "description": "Worker organizing has emerged as a critical force in preventing tech-enabled harms, with employees playing a pivotal role in halting harmful projects, exposing unethical practices, and demanding improved conditions. Yet, many have faced serious retaliation, underscoring the urgent need for robust labor and whistleblower protections. Embedding these safeguards into tech policy is essential for fostering an industry grounded in accountability, ethics, and justice—one where organized worker power is recognized as a foundation for long-term structural change.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 2,
    "channel": "Workers’ Bargaining Power"
  },
  {
    "index": 32,
    "title": "Data Minimization Rules",
    "description": "Stronger data minimization rules offer a promising path toward AI accountability by limiting excessive and harmful data collection. While past enforcement under frameworks like the GDPR has been lax and ambiguous, emerging proposals call for clearer, enforceable limits. Advocated by civil society groups, these bright-line policies could curb exploitative AI practices and challenge the data-intensive business models that underlie many of the most troubling AI systems.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 2,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 33,
    "title": "Legal Protection for Data Access",
    "description": "While data access for vetted researchers is essential for transparency and accountability, relying solely on it is a weak policy response, especially as independent research spaces shrink. Legal protections—such as safe-harbor provisions for web scraping—are crucial to shield good-faith researchers from legal risk under laws like the CFAA. Additionally, community-based research must be supported with both legal safeguards and adequate funding. However, overreliance on access provisions can backfire by placing undue responsibility on under-resourced actors and allowing platforms to control the terms of scrutiny, thereby weakening broader structural accountability efforts.",
    "references": "2023 Landscape: Confronting Tech Power",
    "type": "Public Policy",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 34,
    "title": "Bias-Aware Preprocessing",
    "description": "Addressing algorithmic bias begins with preprocessing the training data to ensure it accurately reflects diverse populations, especially historically marginalized groups. Techniques like oversampling underrepresented data, undersampling dominant groups, or generating synthetic data help balance representation, reducing the risk of encoding systemic inequalities into AI models before training even begins.",
    "references": "2304.07683 Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 35,
    "title": "Adversarial Debiasing",
    "description": "Adversarial debiasing is a model training technique designed to reduce bias by introducing a secondary adversary network that tries to predict protected attributes from the model’s outputs. The main model is trained to perform well on the primary task while minimizing the adversary’s success, thereby making the model more resilient to specific forms of bias and better aligned with fairness goals.",
    "references": "2304.07683 Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 36,
    "title": "Fairness-Aware Classifiers",
    "description": "One approach to mitigating algorithmic bias involves selecting classifiers that satisfy demographic parity—ensuring that outcomes are distributed equally across groups defined by protected attributes. By aligning model outputs with fairness constraints, this method helps prevent systemic disparities in decisions, promoting equitable treatment across populations.",
    "references": "2304.07683 Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 37,
    "title": "Fairness-Based Model Selection",
    "description": "Model selection techniques that prioritize fairness can be guided by either group fairness—ensuring equitable outcomes across different demographic groups—or individual fairness, which focuses on treating similar individuals similarly. By incorporating these fairness metrics during the model evaluation and selection phase, developers can choose models that not only perform well but also align with ethical standards and reduce discriminatory outcomes.",
    "references": "2304.07683 Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 38,
    "title": "Post-Processing Fairness",
    "description": "Bias mitigation can also occur after model training through post-processing techniques that adjust model outputs to meet fairness criteria. One prominent method aims to achieve equalized odds by ensuring that error rates—such as false positives and false negatives—are evenly distributed across demographic groups. This approach helps correct for discriminatory patterns without altering the model’s internal structure.",
    "references": "2304.07683 Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 1,
    "channel": "Algorithmic Justice"
  },
  {
    "index": 39,
    "title": "AI Risk Insurance",
    "description": "As AI systems grow in complexity and autonomy, they introduce significant financial and liability risks due to their unpredictable behavior. Insurance can play a crucial role in managing these risks, both by enabling transactions under uncertainty and by incentivizing responsible development through risk-based pricing and underwriting standards. By addressing complex issues like joint causation and system breaches, insurance markets could shape governance norms, dampen speculative hype, and improve transparency around AI-related risks. The creation of tailored insurance products could thus support both innovation and accountability in the AI sector.",
    "references": "AI Governance through Markets",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Information Symmetry"
  },
  {
    "index": 40,
    "title": "System Audits",
    "description": "Third-party auditing and certification serve as key mechanisms for ensuring transparency, accountability, and compliance in corporate and technological practices. In the AI sector, audits can help bridge the gap between proprietary system opacity and the need for public oversight by offering independent assessments without compromising security. These mechanisms not only foster trust among stakeholders and support regulatory efforts, but also incentivize firms to improve internal controls and uphold commitments. As such, audits play a central role in aligning corporate behavior with public safety, investor confidence, and scientific understanding of AI systems.",
    "references": "AI Governance through Markets",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Information Symmetry"
  },
  {
    "index": 41,
    "title": "Procurement Standards",
    "description": "AI procurement standards are rapidly evolving to address issues of safety, transparency, and accountability, particularly as governments increasingly rely on private contractors for AI development. While emerging guidelines aim to support secure and responsible AI adoption, there is a pressing need for more robust, sector-wide procurement norms beyond defense. The U.S. military’s extensive procurement system exemplifies how stringent standards can shape market behavior, incentivize innovation, and set global benchmarks. However, these frameworks can also raise entry barriers and limit competition, highlighting the trade-offs between regulatory rigor and market inclusivity.",
    "references": "AI Governance through Markets",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Information Symmetry"
  },
  {
    "index": 42,
    "title": "Investor Due Diligence",
    "description": "Investor due diligence is a critical governance mechanism that helps mitigate information asymmetry by enabling investors to assess both risks and opportunities before committing capital. In the context of AI, where financial risks and operational opacity can be high, due diligence not only pressures companies to uphold transparency and regulatory compliance but also sets informal market standards for responsible AI practices. This process acts as both an incentive and a safeguard, encouraging firms to maintain robust governance while guiding investor decisions in an increasingly AI-driven economy.",
    "references": "AI Governance through Markets",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Information Symmetry"
  },
  {
    "index": 43,
    "title": "Standardised Disclosure",
    "description": "Widespread information asymmetry and uncertainty around emerging technologies hinder effective market functioning and resource allocation. Stakeholders such as investors, insurers, and procurement bodies require accurate, consistent data to assess risks, set standards, and guide capital flows. Standardised disclosure offers a solution by creating a shared informational baseline, reducing transaction costs, and promoting competition based on value. By improving transparency, it enables more informed decision-making and helps mitigate the societal risks posed by opaque technological systems.",
    "references": "AI Governance through Markets",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Information Symmetry"
  },
  {
    "index": 44,
    "title": "Risk Framework Disclosure",
    "description": "Standardisation helps demystify complex technological risks, enabling non-experts across sectors like investment, insurance, and procurement to make more informed decisions. The lack of uniform metrics for assessing risks creates inefficiencies and hampers capital allocation. A common risk framework provides consistent, accessible tools for evaluating and communicating potential harms, even if it cannot fully capture every nuance. Research communities can support this governance effort by developing standardized methods to describe and quantify key system features, fostering more transparent and effective decision-making across the market.",
    "references": "AI Governance through Markets",
    "type": "Market Mechanism",
    "aiWorld": "AI as Normal Technology",
    "level": 0,
    "channel": "Information Symmetry"
  }
]